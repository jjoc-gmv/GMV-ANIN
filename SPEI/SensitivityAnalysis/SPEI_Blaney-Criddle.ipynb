{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from pyproj import CRS\n",
    "from shapely.geometry import mapping\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "\n",
    "import climate_indices\n",
    "from climate_indices import indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SETTING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################ SETTING PARAMETERS  for the SPI #################################################################\n",
    "\n",
    "scale = 3\n",
    "distribution = climate_indices.indices.Distribution.gamma   #Fixed\n",
    "data_start_year = 1980\n",
    "calibration_year_initial = 1980\n",
    "calibration_year_final = 2023\n",
    "periodicity = climate_indices.compute.Periodicity.monthly   #Fixed\n",
    "\n",
    "######################################################################################### CRS ############################################################################\n",
    "\n",
    "crs_project = CRS.from_epsg(4326) #WGS84\n",
    "\n",
    "######################################################################################### INPUTS ############################################################################\n",
    "\n",
    "ERA5_input_path = 'Insert path to monthly ERA5_land data'\n",
    "ERA5_daily_input_folder =  'Insert path to daily ERA5_land data'\n",
    "\n",
    "######################################################################################### OUPUTS ############################################################################\n",
    "\n",
    "path_out = 'Insert path to the output directory'\n",
    "SPEI_ouput_file = 'Insert output file name'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MASK FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "def load_shape_file(filepath):\n",
    "    \"\"\"Loads the shape file desired to mask a grid.\n",
    "    Args:\n",
    "        filepath: Path to *.shp file\n",
    "    \"\"\"\n",
    "    shpfile = gpd.read_file(filepath)\n",
    "    print(\"\"\"Shapefile loaded. To prepare for masking, run the function\n",
    "        `select_shape`.\"\"\")\n",
    "    return shpfile\n",
    "\n",
    "#Create the mask\n",
    "def select_shape(shpfile):\n",
    "    \"\"\"Select the submask of interest from the shapefile.\n",
    "    Args:\n",
    "        shpfile: (*.shp) loaded through `load_shape_file`\n",
    "        category: (str) header of shape file from which to filter shape.\n",
    "            (Run print(shpfile) to see options)\n",
    "        name: (str) name of shape relative to category.\n",
    "           Returns:\n",
    "        shapely polygon\n",
    "    \"\"\"\n",
    "\n",
    "    col_code = 'ISO3_CODE'\n",
    "    country_codes = ['ZAF', 'LSO', 'SWZ']\n",
    "\n",
    "    # Extract the rows that have 'ZAF', 'LSO', or 'SWZ' in the 'SOV_A3' column\n",
    "    selected_rows = shpfile[shpfile[col_code].isin(country_codes)]\n",
    "\n",
    "    # Combine the selected polygons into a single polygon\n",
    "    unioned_polygon = selected_rows.geometry.unary_union\n",
    "\n",
    "    # Convert the unioned polygon to a geopandas dataframe with a single row\n",
    "    mask_polygon = gpd.GeoDataFrame(geometry=[unioned_polygon])\n",
    "    \n",
    "    print(\"\"\"Mask created.\"\"\")\n",
    "\n",
    "    return mask_polygon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MASK LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load de shp\n",
    "shpfile = load_shape_file('Insert path to the shp CNTR_RG_01M_2020_4326.shp') #Boundaries\n",
    "\n",
    "#Create the mask layer\n",
    "mask_layer = select_shape(shpfile)\n",
    "\n",
    "#Giving a CRS\n",
    "mask_layer.crs = crs_project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VARIABLE PROCESSING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERA5 TEMPERATURE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_temp_files = glob.glob(os.path.join(ERA5_daily_input_folder, '*.nc'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemperaturesData(temp_data):\n",
    "    \"\"\"Process the data to get daily max, mean and min temperatures as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with hourly temperature data\n",
    "\n",
    "        Returns\n",
    "        Three dataarray for Tmax, Tmin and Tmean with monthly values\n",
    "    \"\"\"  \n",
    "    scale_factor =  temp_data.attrs['scale_factor']\n",
    "    offset = temp_data.attrs['add_offset']\n",
    "    temp_data = (temp_data * scale_factor) + offset #Rescaling the values\n",
    "\n",
    "    #Create 3 variables for daily tmean\n",
    "    temp_tmean = temp_data.resample(time ='D').mean()-273.15\n",
    "\n",
    "    # Resample data from daily into monthly. \n",
    "\n",
    "    temp_tmean = temp_tmean.resample(time ='M').mean()\n",
    "\n",
    "    # Resample original data from hourly into monthly to have the structure\n",
    "    temperatures = temp_data.resample(time='M').mean()\n",
    "\n",
    "    #Putting all together\n",
    "    temperatures['tmean'] = temp_tmean\n",
    "\n",
    "    #Separate in variables\n",
    "    tmean = temperatures['tmean']\n",
    "    tmean = tmean.reindex(y=list(reversed(tmean['y']))) # Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    tmean.rio.write_crs(crs_project, inplace=True)\n",
    "\n",
    "    #Mask the country\n",
    "    tmean_masked = tmean.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "    return tmean_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean_list = []\n",
    "\n",
    "#Applying the function to each one of the files with hourly data. Appending the result in separate variable lists\n",
    "for file in daily_temp_files:\n",
    "    data = rxr.open_rasterio(file, masked=True)\n",
    "    tmean_masked = getTemperaturesData(data)\n",
    "    tmean_list.append(tmean_masked)\n",
    "\n",
    "#Creating an xarray for each temp variable\n",
    "Tmean = xr.concat(tmean_list, dim='time')\n",
    "\n",
    "#Changing time format\n",
    "Tmean['time'] = Tmean['time'].astype('datetime64[ns]')\n",
    "\n",
    "#Cleaning\n",
    "Tmean = Tmean.drop_vars('tmean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERA5 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "data = rxr.open_rasterio(ERA5_input_path, masked=True)\n",
    "#Giving a CRS\n",
    "data.rio.write_crs(crs_project, inplace=True)\n",
    "data['time'] = data['time'].astype('datetime64[ns]')  # Change to datetime format to fix with te temp data ahead\n",
    "\n",
    "data = data.assign_coords(time=pd.to_datetime(data.time.values) + pd.offsets.MonthEnd(1))   #Change the first day of the month for the last day of the month"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract and give shape to the precipitation data\n",
    "def getPrecipData(precip_data):\n",
    "    \"\"\"Process the data to get precipitation as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with precip data\n",
    "\n",
    "        Returns\n",
    "        DataArrayGroupBy grouped over point (y and x coordinates)\n",
    "    \"\"\"\n",
    "    num_days_month = precip_data.time.dt.days_in_month #Necessary to multiply the daily values of the mean to the \"size\" of the month\n",
    "\n",
    "    scale_factor =  precip_data.attrs['scale_factor']\n",
    "    offset = precip_data.attrs['add_offset']\n",
    "    precip = (precip_data * scale_factor) + offset #Rescaling the values\n",
    "    precip = precip*1000*num_days_month  # The original units are meters, we change them to milimeters, and multiply by the days of the month\n",
    "    \n",
    "# Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    precip = precip.rename({'y': 'lat', 'x':'lon'})       #Necessary step\n",
    "    precip = precip.reindex(lat=list(reversed(precip['lat'])))\n",
    "    precip = precip.rename({'lat': 'y', 'lon':'x'})\n",
    "\n",
    "#Mask the country\n",
    "    precip_masked = precip.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "#Giving the appropriate shape to da data\n",
    "    precip_grouped = precip_masked.stack(point=('y', 'x')).groupby('point')\n",
    "    print(\"\"\"Precipitation data is prepared to serve\n",
    "        as input for the SPEI index.\"\"\")\n",
    "\n",
    "    return precip_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get precipitation data\n",
    "precip_data = data['tp']\n",
    "precips_mm = getPrecipData(precip_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean daylight hours (N) for the 15th of the month. -30ยบ latitud kind of average\n",
    "###### https://www.fao.org/3/x0490e/x0490e0j.htm#annex%202.%20meteorological%20tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdh = {\n",
    "    \"01\": 13.7,\n",
    "    \"02\": 13,\n",
    "    \"03\": 12.2,\n",
    "    \"04\": 11.3,\n",
    "    \"05\": 10.5,\n",
    "    \"06\": 10.1,\n",
    "    \"07\": 10.2,\n",
    "    \"08\": 10.9,\n",
    "    \"09\": 11.8,\n",
    "    \"10\": 12.7,\n",
    "    \"11\": 13.5,\n",
    "    \"12\": 13.9 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumatory of the mean values of daylight\n",
    "tota_hours_year = sum(mdh.values())\n",
    "#Getting percentages for each month\n",
    "mdh_perc = {key: (value / tota_hours_year) * 100 for key, value in mdh.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdh_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meses = Tmean['time'].dt.strftime('%m').values\n",
    "meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_resultado = np.array([mdh_perc[mes] for mes in meses])\n",
    "array_resultado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ET0 function BLANEY-CRIDDLE EQUATION\n",
    "def get_pet_mm(Tmean, mdh_perc):\n",
    "    month = Tmean['time'].dt.strftime('%m').values\n",
    "    ro = xr.DataArray([mdh_perc[m] for m in month], dims=('time',))\n",
    "    pet_mm = ro * ( ( 0.46 * Tmean ) + 8.13 )\n",
    "    print(pet_mm)\n",
    "    \n",
    "    return pet_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation pet\n",
    "pet_mm = get_pet_mm(Tmean, mdh_perc)\n",
    "\n",
    "#Giving the appropriate shape to da data. Grouping\n",
    "pet_mm_grouped = pet_mm.stack(point=('y', 'x')).groupby('point')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPLY SPEI FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####https://github.com/monocongo/climate_indices\n",
    "spei_values = xr.apply_ufunc(indices.spei,\n",
    "                            precips_mm,\n",
    "                            pet_mm_grouped, \n",
    "                            scale,\n",
    "                            distribution,\n",
    "                            periodicity,\n",
    "                            data_start_year,\n",
    "                            calibration_year_initial,\n",
    "                            calibration_year_final\n",
    "                            )                 \n",
    "\n",
    "# Unstack the array back into original dimensions\n",
    "spei_results = spei_values.unstack('point')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give CRS and reprojecto to match the data source\n",
    "spei_results = spei_results.rio.write_crs(\"EPSG:4326\")\n",
    "spei_results = spei_results.rio.reproject_match(data, resampling = Resampling.bilinear, nodata=np.nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spei_results.to_netcdf(f'{path_out}{SPEI_ouput_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4213db1b92f27a0df3bdb0f8c208fc37d0294f1bbcda358f5217b3f00267894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
